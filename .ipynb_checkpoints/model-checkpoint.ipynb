{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90c5f07a-1c30-4586-bb8f-f70b87adc12c",
   "metadata": {},
   "source": [
    "# Import Statements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baadcca0-d4ae-4180-8db4-7b4735b0d8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3236f682-ce3d-4ba0-9228-e1c194fdab44",
   "metadata": {},
   "source": [
    "# Steps\n",
    "    * Get dataset of small set, and cpu from cudi nvida\n",
    "    * Proprocess data and resize\n",
    "    * make nueral network\n",
    "    * using YOLO method openCV object detection \n",
    "    * make first draft of model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad52038-abda-4702-9318-a7103e4485ae",
   "metadata": {},
   "source": [
    "# Getting dataset\n",
    "    * Dataset is from https://www.kaggle.com/datasets/asdasdasasdas/garbage-classification\n",
    "    * 6 classes of material this for first draft of a model\n",
    "    * make more comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "33622451-7d4f-4589-8066-beb4e256622a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "IMAGE_SIZE =  224\n",
    "# training 50 times first \n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4695d959-a49c-4729-9a9e-5c39096e5ac4",
   "metadata": {},
   "source": [
    "    *Merging multiple folders in specific recylce,trash,organic dataset to put in 3 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0598c8a-63dd-42f5-b0a9-ca33dcc65c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dirs = [\n",
    "    'C:\\\\Users\\\\snehd\\\\Ai-Trash-Recognition\\\\Waste Classification Dataset\\\\Garbage classification\\\\recyclable\\\\glass',\n",
    "    'C:\\\\Users\\\\snehd\\\\Ai-Trash-Recognition\\\\Waste Classification Dataset\\\\Garbage classification\\\\recyclable\\\\metal',\n",
    "    'C:\\\\Users\\\\snehd\\\\Ai-Trash-Recognition\\\\Waste Classification Dataset\\\\Garbage classification\\\\recyclable\\\\plastic'\n",
    "    \n",
    "]\n",
    "\n",
    "# Destination directory (current folder)\n",
    "dest_dir = 'C:\\\\Users\\\\snehd\\\\Ai-Trash-Recognition\\\\Waste Classification Dataset\\\\Garbage classification\\\\recyclable'\n",
    "\n",
    "# Move each file from the source directories to the destination directory\n",
    "for directory in source_dirs:\n",
    "    for file in os.listdir(directory):\n",
    "        src_path = os.path.join(directory, file)\n",
    "        dest_path = os.path.join(dest_dir, file)\n",
    "        # Check if file already exists in destination to prevent overwriting\n",
    "        if not os.path.exists(dest_path):\n",
    "            shutil.move(src_path, dest_path)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5c85e3-ccde-45a7-b5e0-f8f3e0142546",
   "metadata": {},
   "outputs": [],
   "source": [
    "* Preprocessing image and shuffling using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "28ede06e-6a6b-41d0-b516-84930b9e1a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = r\"C:\\Users\\snehd\\Ai-Trash-Recognition\\Garbage classification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d30a70b8-df04-4c05-977f-15f5cb3da187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27232 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory = dataset_dir,\n",
    "    shuffle = True,\n",
    "    image_size = (IMAGE_SIZE,IMAGE_SIZE),\n",
    "    batch_size = 32   \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e844b6c0-da29-42cb-9690-5137ce8017be",
   "metadata": {},
   "source": [
    "# Making Model\n",
    "    *using Keras sequential building intial draft of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dd609bba-f9d8-4a9d-9274-56721bd9322d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['organic', 'recyclable', 'trash']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = dataset.class_names\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4827800b-c5d4-45d7-921f-3347b449f424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "851"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdfe9655-87f8-4771-98ef-3cbfd38acabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Test Train Split\n",
    "# deciding to train 80% and test 20% for first draft of model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54dc2e7-15b7-4a9b-8b52-ae83e9acae5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
